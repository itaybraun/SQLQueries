-----------------------------
-- General & Configuration --
-----------------------------
-- Current User, DB...  https://www.postgresql.org/docs/9.1/functions-info.html 
SELECT current_user, current_catalog, version() ;

 --https://www.postgresql.org/docs/9.1/view-pg-settings.html
 --The view pg_settings provides access to run-time parameters of the server. It is essentially an alternative interface to the SHOW and SET commands. It also provides access to some facts about each parameter that are not directly available from SHOW, such as minimum and maximum values.
 SELECT * FROM pg_settings WHERE name like '%log%';
  SELECT * FROM pg_settings WHERE name like '%share%';
 
 --https://www.postgresql.org/docs/9.1/sql-show.html
 SHOW ALL
 --change values using ALTER SYSTEM: https://www.postgresql.org/docs/10/sql-altersystem.html 
 
 --After updating the config and running SELECT pg_reload_conf() to reload the config, Postgres will start logging all queries that take over the threshold.
 SELECT pg_reload_conf()

SELECT * FROM pg_available_extensions WHERE name = 'pg_stat_statements'
SELECT * FROM pg_available_extension_versions WHERE name = 'pg_stat_statements'  
and  installed is true;
-----------------------------
 -- 		Schema			--
 -----------------------------

-- User Tables
SELECT * 
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog','information_schema');

--Indexes
 SELECT * FROM pg_indexes WHERE schemaname = 'public';

-----------------------
-- 		Storage		 --
-----------------------

--DB Size
SELECT pg_size_pretty( pg_database_size('postgres') );

--Table (Relation) size. Indexes are also seen as relations
SELECT pg_size_pretty( pg_total_relation_size('country') );

--https://wiki.postgresql.org/wiki/Disk_Usage
--	Query: General Table Size Information Grouped For Partitioned Tables
--	Desc: This will report size information for all tables, that are not inherited, in the "pretty" form. Inherited tables are grouped together.
-- TODO: do not show the pg-catalog schema. 
--	Granularity: table_schema, table_name
 xcvbn mbvcvb
-- Query: General Table Size Information
--	Desc: This will report size information for all tables, in both raw bytes and "pretty" form.
--	Granularity: oid 
SELECT *, pg_size_pretty(total_bytes) AS total
    , pg_size_pretty(index_bytes) AS index
    , pg_size_pretty(toast_bytes) AS toast
    , pg_size_pretty(table_bytes) AS table
  FROM (
  SELECT *, total_bytes-index_bytes-coalesce(toast_bytes,0) AS table_bytes FROM (
      SELECT c.oid,nspname AS table_schema, relname AS table_name
              , c.reltuples AS row_estimate
              , pg_total_relation_size(c.oid) AS total_bytes
              , pg_indexes_size(c.oid) AS index_bytes
              , pg_total_relation_size(reltoastrelid) AS toast_bytes
          FROM pg_class c
          LEFT JOIN pg_namespace n ON n.oid = c.relnamespace
          WHERE relkind = 'r'
  ) a
) a;

-- Query: Finding the size of your biggest relations
-- Desc: Relations are objects in the database such as tables and indexes, and this query shows the size of all the individual parts. Tables which have both regular and TOAST pieces will be broken out into separate components; 
--		Only on the current DB
--	Granularity: relation
--	Notes: TOAST (The Oversized-Attribute Storage Technique). URL: https://www.postgresql.org/docs/current/storage-toast.html 
SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_relation_size(C.oid)) AS "size"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
  ORDER BY pg_relation_size(C.oid) DESC
  LIMIT 20;
  
  
--Query: Finding the total size of your biggest tables
-- Desc: This version of the query uses pg_total_relation_size, which sums total disk space used by the table including indexes and toasted data rather than breaking out the individual pieces:
-- Notes: pg_total_relation_size; URL: https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADMIN-DBSIZE
-- Granularity: relation (which is schema.objectname)
SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_total_relation_size(C.oid)) AS "total_size"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
    AND C.relkind <> 'i'
    AND nspname !~ '^pg_toast'
  ORDER BY pg_total_relation_size(C.oid) DESC
  LIMIT 20;

  ----------------------------------
  --		LOG				--
  ----------------------------
  -- https://www.postgresql.org/docs/current/pgstatstatements.html
  -- Requires configuration of the min value to collect + a restart. 
  SELECT * FROM pg_stat_statements; 
  --pg_stat_statements.track = ALL
  
  --Top CPU
  SELECT total_time, query
FROM pg_stat_statements
ORDER BY total_time
DESC LIMIT 10;

--Longest queries on avg. Does it group the quereis as in the query store?
SELECT mean_time, query
FROM pg_stat_statements
ORDER BY mean_time
DESC LIMIT 10;

-- get the top 5 duration queries executed during your performance/benchmarking run:
SELECT query, calls, total_time, rows, 100.0 * shared_blks_hit/           
nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
ORDER BY total_time
DESC LIMIT 5

  
  -- Query: Which Top 3 queries were burning the most CPU time between times t1 and t2 and approximately how much of the total Postgres runtime it represented:
  -- https://www.cybertec-postgresql.com/en/a-quick-pg_stat_statements-troubleshooting-hack/
  explain
with q_snap_data as (
  select
    ts,
    queryid,
    max(query) as query, /* avoiding groupings over long text values is a good idea generally */
    sum(total_time) as total_time,
    sum(calls) as calls
  from
    stat_statements_snapshots
  where
    not query like 'insert into stat_statements_snapshots%' /* don't include our snapshot collecting query */
  group by
    ts, queryid /* 1st gruping needed as queries have separate rows for various users which we want to ignore */
),
q_min_total as (
  select sum(total_time) as min from q_snap_data group by ts order by ts limit 1
),
q_max_total as (
  select sum(total_time) as max from q_snap_data group by ts order by ts desc limit 1
)
select
  queryid,
  max(query) as query,
  max(total_time) - min(total_time) as total_time,
  max(calls) - min(calls) as calls,
  (max(total_time) - min(total_time)) / (max(calls) - min(calls)) as mean_time,
  100 * (max(total_time) - min(total_time))::numeric / (select max - min from q_max_total, q_min_total) as approx_pct_of_total
from
  q_snap_data
/*where
  ts between t1 and t2 */
group by
  queryid
having
  max(calls) > min(calls)
order by
  total_time desc
limit
  3;
  
  --Query: What queries had the biggest (absolute) execution time change compared to the hour before:
  with q_snap_data as (
  select
    ts,
    queryid,
    max(query) as query, /* avoiding grupings over long text values is a good idea generally */
    sum(total_time) as total_time,
    sum(calls) as calls
  from
    stat_statements_snapshots
  where
    not query like 'insert into stat_statements_snapshots%' /* don't include our snapshot collecting query */
    /* and ts between t1 and t2 */
  group by
    ts, queryid /* 1st grouping needed as queries have separate rows for various users which we want to ignore */
),
q_snap_data_hour as (
  select
    extract(hour from ts) as ts,
    queryid,
    max(query) as query,
    max(total_time) - min(total_time) as total_time,
    max(calls) - min(calls) as calls
  from
    q_snap_data
  group by
    extract(hour from ts), queryid
)
select
  *,
  total_time - lag_total_time as total_time_growth
from (
select
  ts,
  queryid,
  query,
  total_time,
  lag(total_time) over (partition by queryid order by ts) as lag_total_time,
  calls
from
  q_snap_data_hour
) x
where
  lag_total_time > 0 and total_time > lag_total_time
order by
  total_time - lag_total_time desc
limit
  3;
  
  -- By looking at the total_time and number of times a query is called per query, we can get a really quick view of which queries are very frequently run, as well as what they consume on average:
  -- https://www.citusdata.com/blog/2019/02/08/the-most-useful-postgres-extension-pg-stat-statements/
  SELECT 
  (total_time / 1000 / 60) as total, 
  (total_time/calls) as avg, 
  query 
FROM pg_stat_statements 
ORDER BY 1 DESC 
LIMIT 100;

SELECT pg_stat_statements_reset();

SELECT Query, * FROM pg_stat_activity WHERE query like 'SELECT %';


 --  EXPLAIN -----------

EXPLAIN SELECT * FROM country WHERE country_id = 1;
 EXPLAIN ANALYZE SELECT * FROM country WHERE country_id = 1;
 EXPLAIN SELECT * FROM country WHERE country = 'Angola';
 EXPLAIN ANALYZE SELECT * FROM pg_indexes WHERE tablename='pg_constraint';   --https://wiki.postgresql.org/wiki/Introduction_to_VACUUM,_ANALYZE,_EXPLAIN,_and_COUNT
					-----------------------
					-- 		Security	 --
					-----------------------

--Check whether the current user has a SUPER priviledge. It is needed for operations such as DISABLE ALL TRIGGERS
-- The expected answer for usesuper should be 'true'
select usename, usesuper from pg_user where usename = (select current_user);
 
 --https://www.postgresql.org/docs/current/view-pg-user.html
 --The view pg_user provides access to information about database users. This is simply a publicly readable view of pg_shadow that blanks out the password field.
 SELECT * FROM pg_user;
 
 
